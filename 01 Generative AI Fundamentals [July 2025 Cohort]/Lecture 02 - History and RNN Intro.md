# Lecture 2 - History and RNN Intro

https://zoom.us/clips/share/B1IAB5VxQDSOAgz-SPanNw

## Discord Assistance for Potential Issues

Discussed the availability of assistance through Discord for any issues that may arise.

## Generative AI Minor Course Order and Content

Introduced myself as Dr. Raj Dandekar, one of the co-founders of Vijura and a creator of the minor in generative AI. I clarified the confusion regarding the order of courses and their content.

## Email Discussion and Student Notifications

Discussed the email I sent to all students in the class, which included information about the 1st semester. I also mentioned that I had sent specific emails to Kalis Mohan and Nilesh.

## Generative AI Minor Course Overview

Discussed the structure of the generative AI minor course, which is self-contained and does not require prior ML knowledge.

## Generative AI: From Eliza to Modern Applications

Discussed the history of generative AI, starting with Eliza, a talking robot launched in 1966.

## Evolution of Generative Models: From RNNs to LSTMs

Discussed the evolution of generative models, starting with RNNs and LSTMs, which were widely used for tasks like machine translation and predicting future trends.

## Limitations of Normal Neural Networks in Natural Language Generation

Explained the limitations of normal neural networks in performing tasks like natural language generation.

## Recurrent Neural Networks and Drawing Tool Demonstration

Explained the concept of Recurrent Neural Networks (RNNs) and demonstrated their functionality using a drawing tool.

- RNN are Recurrent Neural networks
- LSTM Long term Short term Memory Model
- Can RNN be used to generate data ?
- How do RNNs look like ?
- There is one general structure whichj repeats over and over again
- https://chatgpt.com/c/68984f78-78b8-832d-8ab1-03dd26bf795d
- https://chatgpt.com/c/68984f78-78b8-832d-8ab1-03dd26bf795d
- https://www.perplexity.ai/search/what-is-the-architecture-of-rn-6MVVVpNbSgGNle7GHHOw2w

## One-Hot Encoding: Representing Unique Characters With Vectors

Explained the concept of one-hot encoding, where each unique character is represented by a vector of zeros and one.

## How RNN Memory Works in Translation Example

Explained how the memory part of Rnn works. I used a translation example to illustrate the process, mentioning that the encoder and decoder are two parts of the Rnn.
