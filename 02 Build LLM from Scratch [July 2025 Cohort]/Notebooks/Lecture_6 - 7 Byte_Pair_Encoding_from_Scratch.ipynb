{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Why does character level tokenization fail?"
      ],
      "metadata": {
        "id": "bHhrmYGJGYYI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzNb6UXDGVIw",
        "outputId": "f8e865f2-73d9-4f4c-bce3-798bed1a073a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word tokens: ['Today,', 'I', 'want', 'to', 'start', 'my', 'day', 'with', 'a', 'cup', 'of', 'coffee']\n",
            "Number of words: 12\n",
            "Character tokens: ['T', 'o', 'd', 'a', 'y', ',', ' ', 'I', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 's', 't', 'a', 'r', 't', ' ', 'm', 'y', ' ', 'd', 'a', 'y', ' ', 'w', 'i', 't', 'h', ' ', 'a', ' ', 'c', 'u', 'p', ' ', 'o', 'f', ' ', 'c', 'o', 'f', 'f', 'e', 'e']\n",
            "Number of characters: 50\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Today, I want to start my day with a cup of coffee\"\n",
        "\n",
        "# Split on whitespace to get individual words\n",
        "words = sentence.split()\n",
        "\n",
        "# Print the list of word tokens\n",
        "print(\"Word tokens:\", words)\n",
        "\n",
        "# Print the total number of words\n",
        "print(\"Number of words:\", len(words))\n",
        "\n",
        "\n",
        "sentence = \"Today, I want to start my day with a cup of coffee\"\n",
        "\n",
        "# Convert the sentence into a list of individual characters\n",
        "characters = list(sentence)\n",
        "\n",
        "# Print the list of character tokens\n",
        "print(\"Character tokens:\", characters)\n",
        "\n",
        "# Print the total number of characters\n",
        "print(\"Number of characters:\", len(characters))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Byte Pair Encoding (BPE) from scratch"
      ],
      "metadata": {
        "id": "JoMWyOeyQ7B2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü¶áü¶áü¶á"
      ],
      "metadata": {
        "id": "MEX_J-vjWVos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Take raw text and tokenize into characters"
      ],
      "metadata": {
        "id": "7swCSW0jTAz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "text = \"\"\"The Dark Knight Rises is a superhero movie released in 2012. It is the final part of Christopher Nolan‚Äôs Dark Knight trilogy, following Batman Begins and The Dark Knight. The film stars Christian Bale as Bruce Wayne/Batman, who has been retired as Batman for eight years after the events of the previous movie.\n",
        "\n",
        "The main villain in the movie is Bane, played by Tom Hardy. Bane is a powerful and intelligent terrorist who threatens Gotham City with destruction. He forces Bruce Wayne to come out of retirement and become Batman again. Anne Hathaway plays Selina Kyle, also known as Catwoman, a skilled thief with her own agenda.\n",
        "\n",
        "The movie is about Bruce Wayne‚Äôs struggle to overcome his physical and emotional challenges to save Gotham. It also shows themes of hope, sacrifice, and resilience. The film has many exciting action scenes, such as a plane hijack and a massive battle in Gotham.\n",
        "\n",
        "In the end, Batman saves the city and inspires the people of Gotham. However, he is believed to have sacrificed his life. The movie ends with a twist, suggesting that Bruce Wayne is alive and has moved on to live a quiet life.\n",
        "\n",
        "The Dark Knight Rises was a big success and is loved by many fans for its epic story, strong characters, and thrilling action.\n",
        "\n",
        "Interstellar is a 2014 epic science fiction drama film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan. It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, and Michael Caine. Set in a dystopian future where Earth is suffering from catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
        "\n",
        "The screenplay had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg. Theoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar. It was Lynda Obst's final film as producer before her death. Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Filming began in late 2013 and took place in Alberta, Klaustur, and Los Angeles. Interstellar uses extensive practical and miniature effects, and the company DNEG created additional digital effects.\n",
        "\n",
        "Interstellar was released in theaters on November 7, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews and grossed $681 million worldwide during its initial theatrical run, making it the tenth-highest-grossing film of 2014. Among its various accolades, Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "## For non-alphabet characters and for a more general purpose code, use this:\n",
        "#tokens = text.encode(\"utf-8\") # raw bytes\n",
        "#tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "\n",
        "# For sake of simplicity, we are only using ASCII character encoding:\n",
        "tokens = [ord(ch) for ch in text]"
      ],
      "metadata": {
        "id": "vso_LnYaQ-lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = list(tokens)  # copy so we don't destroy the original list\n"
      ],
      "metadata": {
        "id": "BtVzO_tlRqli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cc51eSTRrhd",
        "outputId": "8f21d346-f74a-4732-ba68-560ebe456f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 115, 32, 105, 115, 32, 97, 32, 115, 117, 112, 101, 114, 104, 101, 114, 111, 32, 109, 111, 118, 105, 101, 32, 114, 101, 108, 101, 97, 115, 101, 100, 32, 105, 110, 32, 50, 48, 49, 50, 46, 32, 73, 116, 32, 105, 115, 32, 116, 104, 101, 32, 102, 105, 110, 97, 108, 32, 112, 97, 114, 116, 32, 111, 102, 32, 67, 104, 114, 105, 115, 116, 111, 112, 104, 101, 114, 32, 78, 111, 108, 97, 110, 8217, 115, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 116, 114, 105, 108, 111, 103, 121, 44, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 66, 97, 116, 109, 97, 110, 32, 66, 101, 103, 105, 110, 115, 32, 97, 110, 100, 32, 84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 46, 32, 84, 104, 101, 32, 102, 105, 108, 109, 32, 115, 116, 97, 114, 115, 32, 67, 104, 114, 105, 115, 116, 105, 97, 110, 32, 66, 97, 108, 101, 32, 97, 115, 32, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 47, 66, 97, 116, 109, 97, 110, 44, 32, 119, 104, 111, 32, 104, 97, 115, 32, 98, 101, 101, 110, 32, 114, 101, 116, 105, 114, 101, 100, 32, 97, 115, 32, 66, 97, 116, 109, 97, 110, 32, 102, 111, 114, 32, 101, 105, 103, 104, 116, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 116, 104, 101, 32, 101, 118, 101, 110, 116, 115, 32, 111, 102, 32, 116, 104, 101, 32, 112, 114, 101, 118, 105, 111, 117, 115, 32, 109, 111, 118, 105, 101, 46, 10, 10, 84, 104, 101, 32, 109, 97, 105, 110, 32, 118, 105, 108, 108, 97, 105, 110, 32, 105, 110, 32, 116, 104, 101, 32, 109, 111, 118, 105, 101, 32, 105, 115, 32, 66, 97, 110, 101, 44, 32, 112, 108, 97, 121, 101, 100, 32, 98, 121, 32, 84, 111, 109, 32, 72, 97, 114, 100, 121, 46, 32, 66, 97, 110, 101, 32, 105, 115, 32, 97, 32, 112, 111, 119, 101, 114, 102, 117, 108, 32, 97, 110, 100, 32, 105, 110, 116, 101, 108, 108, 105, 103, 101, 110, 116, 32, 116, 101, 114, 114, 111, 114, 105, 115, 116, 32, 119, 104, 111, 32, 116, 104, 114, 101, 97, 116, 101, 110, 115, 32, 71, 111, 116, 104, 97, 109, 32, 67, 105, 116, 121, 32, 119, 105, 116, 104, 32, 100, 101, 115, 116, 114, 117, 99, 116, 105, 111, 110, 46, 32, 72, 101, 32, 102, 111, 114, 99, 101, 115, 32, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 32, 116, 111, 32, 99, 111, 109, 101, 32, 111, 117, 116, 32, 111, 102, 32, 114, 101, 116, 105, 114, 101, 109, 101, 110, 116, 32, 97, 110, 100, 32, 98, 101, 99, 111, 109, 101, 32, 66, 97, 116, 109, 97, 110, 32, 97, 103, 97, 105, 110, 46, 32, 65, 110, 110, 101, 32, 72, 97, 116, 104, 97, 119, 97, 121, 32, 112, 108, 97, 121, 115, 32, 83, 101, 108, 105, 110, 97, 32, 75, 121, 108, 101, 44, 32, 97, 108, 115, 111, 32, 107, 110, 111, 119, 110, 32, 97, 115, 32, 67, 97, 116, 119, 111, 109, 97, 110, 44, 32, 97, 32, 115, 107, 105, 108, 108, 101, 100, 32, 116, 104, 105, 101, 102, 32, 119, 105, 116, 104, 32, 104, 101, 114, 32, 111, 119, 110, 32, 97, 103, 101, 110, 100, 97, 46, 10, 10, 84, 104, 101, 32, 109, 111, 118, 105, 101, 32, 105, 115, 32, 97, 98, 111, 117, 116, 32, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 8217, 115, 32, 115, 116, 114, 117, 103, 103, 108, 101, 32, 116, 111, 32, 111, 118, 101, 114, 99, 111, 109, 101, 32, 104, 105, 115, 32, 112, 104, 121, 115, 105, 99, 97, 108, 32, 97, 110, 100, 32, 101, 109, 111, 116, 105, 111, 110, 97, 108, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 115, 32, 116, 111, 32, 115, 97, 118, 101, 32, 71, 111, 116, 104, 97, 109, 46, 32, 73, 116, 32, 97, 108, 115, 111, 32, 115, 104, 111, 119, 115, 32, 116, 104, 101, 109, 101, 115, 32, 111, 102, 32, 104, 111, 112, 101, 44, 32, 115, 97, 99, 114, 105, 102, 105, 99, 101, 44, 32, 97, 110, 100, 32, 114, 101, 115, 105, 108, 105, 101, 110, 99, 101, 46, 32, 84, 104, 101, 32, 102, 105, 108, 109, 32, 104, 97, 115, 32, 109, 97, 110, 121, 32, 101, 120, 99, 105, 116, 105, 110, 103, 32, 97, 99, 116, 105, 111, 110, 32, 115, 99, 101, 110, 101, 115, 44, 32, 115, 117, 99, 104, 32, 97, 115, 32, 97, 32, 112, 108, 97, 110, 101, 32, 104, 105, 106, 97, 99, 107, 32, 97, 110, 100, 32, 97, 32, 109, 97, 115, 115, 105, 118, 101, 32, 98, 97, 116, 116, 108, 101, 32, 105, 110, 32, 71, 111, 116, 104, 97, 109, 46, 10, 10, 73, 110, 32, 116, 104, 101, 32, 101, 110, 100, 44, 32, 66, 97, 116, 109, 97, 110, 32, 115, 97, 118, 101, 115, 32, 116, 104, 101, 32, 99, 105, 116, 121, 32, 97, 110, 100, 32, 105, 110, 115, 112, 105, 114, 101, 115, 32, 116, 104, 101, 32, 112, 101, 111, 112, 108, 101, 32, 111, 102, 32, 71, 111, 116, 104, 97, 109, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 104, 101, 32, 105, 115, 32, 98, 101, 108, 105, 101, 118, 101, 100, 32, 116, 111, 32, 104, 97, 118, 101, 32, 115, 97, 99, 114, 105, 102, 105, 99, 101, 100, 32, 104, 105, 115, 32, 108, 105, 102, 101, 46, 32, 84, 104, 101, 32, 109, 111, 118, 105, 101, 32, 101, 110, 100, 115, 32, 119, 105, 116, 104, 32, 97, 32, 116, 119, 105, 115, 116, 44, 32, 115, 117, 103, 103, 101, 115, 116, 105, 110, 103, 32, 116, 104, 97, 116, 32, 66, 114, 117, 99, 101, 32, 87, 97, 121, 110, 101, 32, 105, 115, 32, 97, 108, 105, 118, 101, 32, 97, 110, 100, 32, 104, 97, 115, 32, 109, 111, 118, 101, 100, 32, 111, 110, 32, 116, 111, 32, 108, 105, 118, 101, 32, 97, 32, 113, 117, 105, 101, 116, 32, 108, 105, 102, 101, 46, 10, 10, 84, 104, 101, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 115, 32, 119, 97, 115, 32, 97, 32, 98, 105, 103, 32, 115, 117, 99, 99, 101, 115, 115, 32, 97, 110, 100, 32, 105, 115, 32, 108, 111, 118, 101, 100, 32, 98, 121, 32, 109, 97, 110, 121, 32, 102, 97, 110, 115, 32, 102, 111, 114, 32, 105, 116, 115, 32, 101, 112, 105, 99, 32, 115, 116, 111, 114, 121, 44, 32, 115, 116, 114, 111, 110, 103, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 44, 32, 97, 110, 100, 32, 116, 104, 114, 105, 108, 108, 105, 110, 103, 32, 97, 99, 116, 105, 111, 110, 46, 10, 10, 73, 110, 116, 101, 114, 115, 116, 101, 108, 108, 97, 114, 32, 105, 115, 32, 97, 32, 50, 48, 49, 52, 32, 101, 112, 105, 99, 32, 115, 99, 105, 101, 110, 99, 101, 32, 102, 105, 99, 116, 105, 111, 110, 32, 100, 114, 97, 109, 97, 32, 102, 105, 108, 109, 32, 100, 105, 114, 101, 99, 116, 101, 100, 32, 98, 121, 32, 67, 104, 114, 105, 115, 116, 111, 112, 104, 101, 114, 32, 78, 111, 108, 97, 110, 44, 32, 119, 104, 111, 32, 99, 111, 45, 119, 114, 111, 116, 101, 32, 116, 104, 101, 32, 115, 99, 114, 101, 101, 110, 112, 108, 97, 121, 32, 119, 105, 116, 104, 32, 104, 105, 115, 32, 98, 114, 111, 116, 104, 101, 114, 32, 74, 111, 110, 97, 116, 104, 97, 110, 46, 32, 73, 116, 32, 115, 116, 97, 114, 115, 32, 77, 97, 116, 116, 104, 101, 119, 32, 77, 99, 67, 111, 110, 97, 117, 103, 104, 101, 121, 44, 32, 65, 110, 110, 101, 32, 72, 97, 116, 104, 97, 119, 97, 121, 44, 32, 74, 101, 115, 115, 105, 99, 97, 32, 67, 104, 97, 115, 116, 97, 105, 110, 44, 32, 66, 105, 108, 108, 32, 73, 114, 119, 105, 110, 44, 32, 69, 108, 108, 101, 110, 32, 66, 117, 114, 115, 116, 121, 110, 44, 32, 97, 110, 100, 32, 77, 105, 99, 104, 97, 101, 108, 32, 67, 97, 105, 110, 101, 46, 32, 83, 101, 116, 32, 105, 110, 32, 97, 32, 100, 121, 115, 116, 111, 112, 105, 97, 110, 32, 102, 117, 116, 117, 114, 101, 32, 119, 104, 101, 114, 101, 32, 69, 97, 114, 116, 104, 32, 105, 115, 32, 115, 117, 102, 102, 101, 114, 105, 110, 103, 32, 102, 114, 111, 109, 32, 99, 97, 116, 97, 115, 116, 114, 111, 112, 104, 105, 99, 32, 98, 108, 105, 103, 104, 116, 32, 97, 110, 100, 32, 102, 97, 109, 105, 110, 101, 44, 32, 116, 104, 101, 32, 102, 105, 108, 109, 32, 102, 111, 108, 108, 111, 119, 115, 32, 97, 32, 103, 114, 111, 117, 112, 32, 111, 102, 32, 97, 115, 116, 114, 111, 110, 97, 117, 116, 115, 32, 119, 104, 111, 32, 116, 114, 97, 118, 101, 108, 32, 116, 104, 114, 111, 117, 103, 104, 32, 97, 32, 119, 111, 114, 109, 104, 111, 108, 101, 32, 110, 101, 97, 114, 32, 83, 97, 116, 117, 114, 110, 32, 105, 110, 32, 115, 101, 97, 114, 99, 104, 32, 111, 102, 32, 97, 32, 110, 101, 119, 32, 104, 111, 109, 101, 32, 102, 111, 114, 32, 109, 97, 110, 107, 105, 110, 100, 46, 10, 10, 84, 104, 101, 32, 115, 99, 114, 101, 101, 110, 112, 108, 97, 121, 32, 104, 97, 100, 32, 105, 116, 115, 32, 111, 114, 105, 103, 105, 110, 115, 32, 105, 110, 32, 97, 32, 115, 99, 114, 105, 112, 116, 32, 74, 111, 110, 97, 116, 104, 97, 110, 32, 100, 101, 118, 101, 108, 111, 112, 101, 100, 32, 105, 110, 32, 50, 48, 48, 55, 32, 97, 110, 100, 32, 119, 97, 115, 32, 111, 114, 105, 103, 105, 110, 97, 108, 108, 121, 32, 115, 101, 116, 32, 116, 111, 32, 98, 101, 32, 100, 105, 114, 101, 99, 116, 101, 100, 32, 98, 121, 32, 83, 116, 101, 118, 101, 110, 32, 83, 112, 105, 101, 108, 98, 101, 114, 103, 46, 32, 84, 104, 101, 111, 114, 101, 116, 105, 99, 97, 108, 32, 112, 104, 121, 115, 105, 99, 105, 115, 116, 32, 75, 105, 112, 32, 84, 104, 111, 114, 110, 101, 32, 119, 97, 115, 32, 97, 110, 32, 101, 120, 101, 99, 117, 116, 105, 118, 101, 32, 112, 114, 111, 100, 117, 99, 101, 114, 32, 97, 110, 100, 32, 115, 99, 105, 101, 110, 116, 105, 102, 105, 99, 32, 99, 111, 110, 115, 117, 108, 116, 97, 110, 116, 32, 111, 110, 32, 116, 104, 101, 32, 102, 105, 108, 109, 44, 32, 97, 110, 100, 32, 119, 114, 111, 116, 101, 32, 116, 104, 101, 32, 116, 105, 101, 45, 105, 110, 32, 98, 111, 111, 107, 32, 84, 104, 101, 32, 83, 99, 105, 101, 110, 99, 101, 32, 111, 102, 32, 73, 110, 116, 101, 114, 115, 116, 101, 108, 108, 97, 114, 46, 32, 73, 116, 32, 119, 97, 115, 32, 76, 121, 110, 100, 97, 32, 79, 98, 115, 116, 39, 115, 32, 102, 105, 110, 97, 108, 32, 102, 105, 108, 109, 32, 97, 115, 32, 112, 114, 111, 100, 117, 99, 101, 114, 32, 98, 101, 102, 111, 114, 101, 32, 104, 101, 114, 32, 100, 101, 97, 116, 104, 46, 32, 67, 105, 110, 101, 109, 97, 116, 111, 103, 114, 97, 112, 104, 101, 114, 32, 72, 111, 121, 116, 101, 32, 118, 97, 110, 32, 72, 111, 121, 116, 101, 109, 97, 32, 115, 104, 111, 116, 32, 105, 116, 32, 111, 110, 32, 51, 53, 32, 109, 109, 32, 109, 111, 118, 105, 101, 32, 102, 105, 108, 109, 32, 105, 110, 32, 116, 104, 101, 32, 80, 97, 110, 97, 118, 105, 115, 105, 111, 110, 32, 97, 110, 97, 109, 111, 114, 112, 104, 105, 99, 32, 102, 111, 114, 109, 97, 116, 32, 97, 110, 100, 32, 73, 77, 65, 88, 32, 55, 48, 32, 109, 109, 46, 32, 70, 105, 108, 109, 105, 110, 103, 32, 98, 101, 103, 97, 110, 32, 105, 110, 32, 108, 97, 116, 101, 32, 50, 48, 49, 51, 32, 97, 110, 100, 32, 116, 111, 111, 107, 32, 112, 108, 97, 99, 101, 32, 105, 110, 32, 65, 108, 98, 101, 114, 116, 97, 44, 32, 75, 108, 97, 117, 115, 116, 117, 114, 44, 32, 97, 110, 100, 32, 76, 111, 115, 32, 65, 110, 103, 101, 108, 101, 115, 46, 32, 73, 110, 116, 101, 114, 115, 116, 101, 108, 108, 97, 114, 32, 117, 115, 101, 115, 32, 101, 120, 116, 101, 110, 115, 105, 118, 101, 32, 112, 114, 97, 99, 116, 105, 99, 97, 108, 32, 97, 110, 100, 32, 109, 105, 110, 105, 97, 116, 117, 114, 101, 32, 101, 102, 102, 101, 99, 116, 115, 44, 32, 97, 110, 100, 32, 116, 104, 101, 32, 99, 111, 109, 112, 97, 110, 121, 32, 68, 78, 69, 71, 32, 99, 114, 101, 97, 116, 101, 100, 32, 97, 100, 100, 105, 116, 105, 111, 110, 97, 108, 32, 100, 105, 103, 105, 116, 97, 108, 32, 101, 102, 102, 101, 99, 116, 115, 46, 10, 10, 73, 110, 116, 101, 114, 115, 116, 101, 108, 108, 97, 114, 32, 119, 97, 115, 32, 114, 101, 108, 101, 97, 115, 101, 100, 32, 105, 110, 32, 116, 104, 101, 97, 116, 101, 114, 115, 32, 111, 110, 32, 78, 111, 118, 101, 109, 98, 101, 114, 32, 55, 44, 32, 50, 48, 49, 52, 46, 32, 73, 110, 32, 116, 104, 101, 32, 85, 110, 105, 116, 101, 100, 32, 83, 116, 97, 116, 101, 115, 44, 32, 105, 116, 32, 119, 97, 115, 32, 102, 105, 114, 115, 116, 32, 114, 101, 108, 101, 97, 115, 101, 100, 32, 111, 110, 32, 102, 105, 108, 109, 32, 115, 116, 111, 99, 107, 44, 32, 101, 120, 112, 97, 110, 100, 105, 110, 103, 32, 116, 111, 32, 118, 101, 110, 117, 101, 115, 32, 117, 115, 105, 110, 103, 32, 100, 105, 103, 105, 116, 97, 108, 32, 112, 114, 111, 106, 101, 99, 116, 111, 114, 115, 46, 32, 84, 104, 101, 32, 102, 105, 108, 109, 32, 114, 101, 99, 101, 105, 118, 101, 100, 32, 103, 101, 110, 101, 114, 97, 108, 108, 121, 32, 112, 111, 115, 105, 116, 105, 118, 101, 32, 114, 101, 118, 105, 101, 119, 115, 32, 97, 110, 100, 32, 103, 114, 111, 115, 115, 101, 100, 32, 36, 54, 56, 49, 32, 109, 105, 108, 108, 105, 111, 110, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 32, 100, 117, 114, 105, 110, 103, 32, 105, 116, 115, 32, 105, 110, 105, 116, 105, 97, 108, 32, 116, 104, 101, 97, 116, 114, 105, 99, 97, 108, 32, 114, 117, 110, 44, 32, 109, 97, 107, 105, 110, 103, 32, 105, 116, 32, 116, 104, 101, 32, 116, 101, 110, 116, 104, 45, 104, 105, 103, 104, 101, 115, 116, 45, 103, 114, 111, 115, 115, 105, 110, 103, 32, 102, 105, 108, 109, 32, 111, 102, 32, 50, 48, 49, 52, 46, 32, 65, 109, 111, 110, 103, 32, 105, 116, 115, 32, 118, 97, 114, 105, 111, 117, 115, 32, 97, 99, 99, 111, 108, 97, 100, 101, 115, 44, 32, 73, 110, 116, 101, 114, 115, 116, 101, 108, 108, 97, 114, 32, 119, 97, 115, 32, 110, 111, 109, 105, 110, 97, 116, 101, 100, 32, 102, 111, 114, 32, 102, 105, 118, 101, 32, 97, 119, 97, 114, 100, 115, 32, 97, 116, 32, 116, 104, 101, 32, 56, 55, 116, 104, 32, 65, 99, 97, 100, 101, 109, 121, 32, 65, 119, 97, 114, 100, 115, 44, 32, 119, 105, 110, 110, 105, 110, 103, 32, 66, 101, 115, 116, 32, 86, 105, 115, 117, 97, 108, 32, 69, 102, 102, 101, 99, 116, 115, 46, 10, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Write a function to count the frequency of the adjacent pairs of characters"
      ],
      "metadata": {
        "id": "EhtGo95DVW58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Count all adjacent pairs in our current sequence 'ids'.\n",
        "\n",
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "stats = get_stats(ids)\n",
        "print(stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwQ_jZmJR0Am",
        "outputId": "f4df6100-a894-4c71-c80d-896dddef0c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(84, 104): 8, (104, 101): 20, (101, 32): 42, (32, 68): 4, (68, 97): 4, (97, 114): 9, (114, 107): 4, (107, 32): 5, (32, 75): 5, (75, 110): 4, (110, 105): 4, (105, 103): 7, (103, 104): 5, (104, 116): 5, (116, 32): 14, (32, 82): 2, (82, 105): 2, (105, 115): 16, (115, 101): 3, (101, 115): 12, (115, 32): 39, (32, 105): 14, (32, 97): 31, (97, 32): 9, (32, 115): 15, (115, 117): 4, (117, 112): 1, (112, 101): 3, (101, 114): 10, (114, 104): 1, (114, 111): 3, (111, 32): 10, (32, 109): 10, (109, 111): 7, (111, 118): 8, (118, 105): 7, (105, 101): 9, (32, 114): 4, (114, 101): 9, (101, 108): 4, (108, 101): 8, (101, 97): 3, (97, 115): 10, (101, 100): 8, (100, 32): 18, (105, 110): 15, (110, 32): 16, (32, 50): 1, (50, 48): 1, (48, 49): 1, (49, 50): 1, (50, 46): 1, (46, 32): 9, (32, 73): 2, (73, 116): 2, (32, 116): 20, (116, 104): 20, (32, 102): 8, (102, 105): 5, (110, 97): 3, (97, 108): 8, (108, 32): 4, (32, 112): 8, (112, 97): 1, (114, 116): 1, (32, 111): 9, (111, 102): 5, (102, 32): 6, (32, 67): 4, (67, 104): 2, (104, 114): 4, (114, 105): 7, (115, 116): 10, (116, 111): 7, (111, 112): 3, (112, 104): 2, (114, 32): 5, (32, 78): 1, (78, 111): 1, (111, 108): 2, (108, 97): 5, (97, 110): 24, (110, 8217): 1, (8217, 115): 2, (116, 114): 4, (105, 108): 7, (108, 111): 3, (111, 103): 1, (103, 121): 1, (121, 44): 2, (44, 32): 13, (102, 111): 4, (108, 108): 6, (111, 119): 6, (119, 105): 5, (110, 103): 6, (103, 32): 6, (32, 66): 12, (66, 97): 8, (97, 116): 10, (116, 109): 5, (109, 97): 10, (66, 101): 1, (101, 103): 1, (103, 105): 1, (110, 115): 4, (110, 100): 13, (32, 84): 5, (116, 46): 1, (108, 109): 2, (109, 32): 4, (116, 97): 1, (114, 115): 3, (116, 105): 9, (105, 97): 1, (66, 114): 4, (114, 117): 6, (117, 99): 7, (99, 101): 10, (32, 87): 4, (87, 97): 4, (97, 121): 7, (121, 110): 4, (110, 101): 9, (101, 47): 1, (47, 66): 1, (110, 44): 2, (32, 119): 6, (119, 104): 2, (104, 111): 4, (32, 104): 10, (104, 97): 12, (32, 98): 7, (98, 101): 3, (101, 101): 1, (101, 110): 11, (101, 116): 3, (105, 114): 3, (111, 114): 5, (32, 101): 7, (101, 105): 1, (32, 121): 1, (121, 101): 2, (97, 102): 1, (102, 116): 1, (116, 101): 5, (101, 118): 4, (118, 101): 12, (110, 116): 4, (116, 115): 2, (112, 114): 1, (105, 111): 5, (111, 117): 3, (117, 115): 1, (101, 46): 4, (46, 10): 5, (10, 10): 5, (10, 84): 3, (97, 105): 3, (32, 118): 1, (101, 44): 4, (112, 108): 4, (98, 121): 2, (121, 32): 7, (84, 111): 1, (111, 109): 5, (32, 72): 4, (72, 97): 2, (114, 100): 1, (100, 121): 1, (121, 46): 1, (112, 111): 1, (119, 101): 2, (114, 102): 1, (102, 117): 1, (117, 108): 1, (108, 105): 9, (103, 101): 4, (114, 114): 1, (32, 71): 4, (71, 111): 4, (111, 116): 5, (97, 109): 4, (67, 105): 1, (105, 116): 7, (116, 121): 2, (104, 32): 4, (32, 100): 1, (100, 101): 1, (99, 116): 4, (111, 110): 6, (110, 46): 3, (72, 101): 1, (114, 99): 2, (32, 99): 4, (99, 111): 3, (109, 101): 5, (117, 116): 2, (101, 109): 3, (101, 99): 1, (97, 103): 2, (103, 97): 1, (32, 65): 1, (65, 110): 1, (110, 110): 1, (97, 119): 1, (119, 97): 2, (121, 115): 2, (32, 83): 1, (83, 101): 1, (75, 121): 1, (121, 108): 1, (108, 115): 2, (115, 111): 2, (32, 107): 1, (107, 110): 1, (110, 111): 1, (119, 110): 2, (67, 97): 1, (116, 119): 2, (119, 111): 1, (115, 107): 1, (107, 105): 1, (104, 105): 4, (101, 102): 1, (100, 97): 1, (97, 46): 1, (97, 98): 1, (98, 111): 1, (101, 8217): 1, (117, 103): 2, (103, 103): 2, (103, 108): 1, (104, 121): 1, (115, 105): 3, (105, 99): 4, (99, 97): 1, (99, 104): 3, (115, 97): 4, (97, 118): 3, (109, 46): 3, (115, 104): 1, (119, 115): 1, (97, 99): 6, (99, 114): 2, (105, 102): 4, (110, 99): 1, (110, 121): 2, (101, 120): 1, (120, 99): 1, (99, 105): 2, (115, 99): 1, (115, 44): 2, (105, 106): 1, (106, 97): 1, (99, 107): 1, (115, 115): 2, (105, 118): 3, (98, 97): 1, (116, 116): 1, (116, 108): 1, (10, 73): 1, (73, 110): 1, (100, 44): 1, (115, 112): 1, (112, 105): 2, (101, 111): 1, (72, 111): 1, (114, 44): 1, (32, 108): 4, (102, 101): 2, (100, 115): 1, (116, 44): 1, (32, 113): 1, (113, 117): 1, (117, 105): 1, (98, 105): 1, (99, 99): 1, (102, 97): 1, (101, 112): 1, (99, 32): 1, (114, 121): 1, (114, 97): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Select the pair with the highest frequency"
      ],
      "metadata": {
        "id": "-voL-MOdVdAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Select the pair with the highest frequency.\n",
        "pair = max(stats, key=stats.get)\n",
        "print(pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZ0crZlR-dC",
        "outputId": "a0f3ceae-24b4-40d9-881d-f37bf199dd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Define the new token's ID (ID of the merged token is added to vocabulary)"
      ],
      "metadata": {
        "id": "Pzhu1x73Viqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Define the new token's ID as 256 + i.\n",
        "i = 0\n",
        "idx = 128 + i\n",
        "print(idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saZaHgdXSIP6",
        "outputId": "1ab2e40b-ec5f-431b-ec94-a3725b04e537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For readability, decode the original token IDs (pair[0], pair[1]) into characters\n",
        "    # just for a nice printout. (Assumes these IDs map to ASCII, etc.)\n",
        "char_pair = (chr(pair[0]), chr(pair[1]))\n",
        "print(char_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFZNOtSSXJJ",
        "outputId": "c13a5151-5aba-44cc-f9a4-8d774e434821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('e', ' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Show which pair we are merging"
      ],
      "metadata": {
        "id": "F1uL6Et9V6_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show which pair we are merging.\n",
        "print(f\"merging {pair} ({char_pair[0]}{char_pair[1]}) into a new token {idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjLr4KISSfF-",
        "outputId": "120879a5-bf3a-4d3b-cb54-2d46661ec286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (101, 32) (e ) into a new token 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Peform the merge: replace all occurences of the most frequent pair with the new token ID"
      ],
      "metadata": {
        "id": "7npSNo-dV-YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Perform the merge, replacing all occurrences of 'pair' with 'idx'.\n",
        "def merge(ids, pair, idx):\n",
        "    newids = []\n",
        "    i = 0\n",
        "    while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
        "            newids.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            newids.append(ids[i])\n",
        "            i += 1\n",
        "    return newids\n",
        "\n",
        "ids = merge(ids, pair, idx)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHw5ObGoSmcG",
        "outputId": "6c0aa4ac-6017-4594-b605-13e8d05c8ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[84, 104, 128, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 115, 32, 105, 115, 32, 97, 32, 115, 117, 112, 101, 114, 104, 101, 114, 111, 32, 109, 111, 118, 105, 128, 114, 101, 108, 101, 97, 115, 101, 100, 32, 105, 110, 32, 50, 48, 49, 50, 46, 32, 73, 116, 32, 105, 115, 32, 116, 104, 128, 102, 105, 110, 97, 108, 32, 112, 97, 114, 116, 32, 111, 102, 32, 67, 104, 114, 105, 115, 116, 111, 112, 104, 101, 114, 32, 78, 111, 108, 97, 110, 8217, 115, 32, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 116, 114, 105, 108, 111, 103, 121, 44, 32, 102, 111, 108, 108, 111, 119, 105, 110, 103, 32, 66, 97, 116, 109, 97, 110, 32, 66, 101, 103, 105, 110, 115, 32, 97, 110, 100, 32, 84, 104, 128, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 46, 32, 84, 104, 128, 102, 105, 108, 109, 32, 115, 116, 97, 114, 115, 32, 67, 104, 114, 105, 115, 116, 105, 97, 110, 32, 66, 97, 108, 128, 97, 115, 32, 66, 114, 117, 99, 128, 87, 97, 121, 110, 101, 47, 66, 97, 116, 109, 97, 110, 44, 32, 119, 104, 111, 32, 104, 97, 115, 32, 98, 101, 101, 110, 32, 114, 101, 116, 105, 114, 101, 100, 32, 97, 115, 32, 66, 97, 116, 109, 97, 110, 32, 102, 111, 114, 32, 101, 105, 103, 104, 116, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 116, 104, 128, 101, 118, 101, 110, 116, 115, 32, 111, 102, 32, 116, 104, 128, 112, 114, 101, 118, 105, 111, 117, 115, 32, 109, 111, 118, 105, 101, 46, 10, 10, 84, 104, 128, 109, 97, 105, 110, 32, 118, 105, 108, 108, 97, 105, 110, 32, 105, 110, 32, 116, 104, 128, 109, 111, 118, 105, 128, 105, 115, 32, 66, 97, 110, 101, 44, 32, 112, 108, 97, 121, 101, 100, 32, 98, 121, 32, 84, 111, 109, 32, 72, 97, 114, 100, 121, 46, 32, 66, 97, 110, 128, 105, 115, 32, 97, 32, 112, 111, 119, 101, 114, 102, 117, 108, 32, 97, 110, 100, 32, 105, 110, 116, 101, 108, 108, 105, 103, 101, 110, 116, 32, 116, 101, 114, 114, 111, 114, 105, 115, 116, 32, 119, 104, 111, 32, 116, 104, 114, 101, 97, 116, 101, 110, 115, 32, 71, 111, 116, 104, 97, 109, 32, 67, 105, 116, 121, 32, 119, 105, 116, 104, 32, 100, 101, 115, 116, 114, 117, 99, 116, 105, 111, 110, 46, 32, 72, 128, 102, 111, 114, 99, 101, 115, 32, 66, 114, 117, 99, 128, 87, 97, 121, 110, 128, 116, 111, 32, 99, 111, 109, 128, 111, 117, 116, 32, 111, 102, 32, 114, 101, 116, 105, 114, 101, 109, 101, 110, 116, 32, 97, 110, 100, 32, 98, 101, 99, 111, 109, 128, 66, 97, 116, 109, 97, 110, 32, 97, 103, 97, 105, 110, 46, 32, 65, 110, 110, 128, 72, 97, 116, 104, 97, 119, 97, 121, 32, 112, 108, 97, 121, 115, 32, 83, 101, 108, 105, 110, 97, 32, 75, 121, 108, 101, 44, 32, 97, 108, 115, 111, 32, 107, 110, 111, 119, 110, 32, 97, 115, 32, 67, 97, 116, 119, 111, 109, 97, 110, 44, 32, 97, 32, 115, 107, 105, 108, 108, 101, 100, 32, 116, 104, 105, 101, 102, 32, 119, 105, 116, 104, 32, 104, 101, 114, 32, 111, 119, 110, 32, 97, 103, 101, 110, 100, 97, 46, 10, 10, 84, 104, 128, 109, 111, 118, 105, 128, 105, 115, 32, 97, 98, 111, 117, 116, 32, 66, 114, 117, 99, 128, 87, 97, 121, 110, 101, 8217, 115, 32, 115, 116, 114, 117, 103, 103, 108, 128, 116, 111, 32, 111, 118, 101, 114, 99, 111, 109, 128, 104, 105, 115, 32, 112, 104, 121, 115, 105, 99, 97, 108, 32, 97, 110, 100, 32, 101, 109, 111, 116, 105, 111, 110, 97, 108, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 115, 32, 116, 111, 32, 115, 97, 118, 128, 71, 111, 116, 104, 97, 109, 46, 32, 73, 116, 32, 97, 108, 115, 111, 32, 115, 104, 111, 119, 115, 32, 116, 104, 101, 109, 101, 115, 32, 111, 102, 32, 104, 111, 112, 101, 44, 32, 115, 97, 99, 114, 105, 102, 105, 99, 101, 44, 32, 97, 110, 100, 32, 114, 101, 115, 105, 108, 105, 101, 110, 99, 101, 46, 32, 84, 104, 128, 102, 105, 108, 109, 32, 104, 97, 115, 32, 109, 97, 110, 121, 32, 101, 120, 99, 105, 116, 105, 110, 103, 32, 97, 99, 116, 105, 111, 110, 32, 115, 99, 101, 110, 101, 115, 44, 32, 115, 117, 99, 104, 32, 97, 115, 32, 97, 32, 112, 108, 97, 110, 128, 104, 105, 106, 97, 99, 107, 32, 97, 110, 100, 32, 97, 32, 109, 97, 115, 115, 105, 118, 128, 98, 97, 116, 116, 108, 128, 105, 110, 32, 71, 111, 116, 104, 97, 109, 46, 10, 10, 73, 110, 32, 116, 104, 128, 101, 110, 100, 44, 32, 66, 97, 116, 109, 97, 110, 32, 115, 97, 118, 101, 115, 32, 116, 104, 128, 99, 105, 116, 121, 32, 97, 110, 100, 32, 105, 110, 115, 112, 105, 114, 101, 115, 32, 116, 104, 128, 112, 101, 111, 112, 108, 128, 111, 102, 32, 71, 111, 116, 104, 97, 109, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 104, 128, 105, 115, 32, 98, 101, 108, 105, 101, 118, 101, 100, 32, 116, 111, 32, 104, 97, 118, 128, 115, 97, 99, 114, 105, 102, 105, 99, 101, 100, 32, 104, 105, 115, 32, 108, 105, 102, 101, 46, 32, 84, 104, 128, 109, 111, 118, 105, 128, 101, 110, 100, 115, 32, 119, 105, 116, 104, 32, 97, 32, 116, 119, 105, 115, 116, 44, 32, 115, 117, 103, 103, 101, 115, 116, 105, 110, 103, 32, 116, 104, 97, 116, 32, 66, 114, 117, 99, 128, 87, 97, 121, 110, 128, 105, 115, 32, 97, 108, 105, 118, 128, 97, 110, 100, 32, 104, 97, 115, 32, 109, 111, 118, 101, 100, 32, 111, 110, 32, 116, 111, 32, 108, 105, 118, 128, 97, 32, 113, 117, 105, 101, 116, 32, 108, 105, 102, 101, 46, 10, 10, 84, 104, 128, 68, 97, 114, 107, 32, 75, 110, 105, 103, 104, 116, 32, 82, 105, 115, 101, 115, 32, 119, 97, 115, 32, 97, 32, 98, 105, 103, 32, 115, 117, 99, 99, 101, 115, 115, 32, 97, 110, 100, 32, 105, 115, 32, 108, 111, 118, 101, 100, 32, 98, 121, 32, 109, 97, 110, 121, 32, 102, 97, 110, 115, 32, 102, 111, 114, 32, 105, 116, 115, 32, 101, 112, 105, 99, 32, 115, 116, 111, 114, 121, 44, 32, 115, 116, 114, 111, 110, 103, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 44, 32, 97, 110, 100, 32, 116, 104, 114, 105, 108, 108, 105, 110, 103, 32, 97, 99, 116, 105, 111, 110, 46, 10, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Write all functions together and define number of iterations to run.\n",
        "\n",
        "Here, we have to select how many merges we do. If we do 20 merges, the vocabulary size increases from 128 to 148."
      ],
      "metadata": {
        "id": "gOhi9-76WJsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "    newids = []\n",
        "    i = 0\n",
        "    while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
        "            newids.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            newids.append(ids[i])\n",
        "            i += 1\n",
        "    return newids\n",
        "\n",
        "# ---\n",
        "vocab_size = 148  # the desired final vocabulary size\n",
        "num_merges = vocab_size - 128\n",
        "ids = list(tokens)  # copy so we don't destroy the original list\n",
        "\n",
        "merges = {}  # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "    # 1) Count all adjacent pairs in our current sequence 'ids'.\n",
        "    stats = get_stats(ids)\n",
        "    pair = max(stats, key=stats.get)\n",
        "    idx = 128 + i\n",
        "    # Decode the characters of the pair for display\n",
        "    char_pair = (chr(pair[0]), chr(pair[1]))\n",
        "    print(f\"merging {pair} ({char_pair[0]}{char_pair[1]}) into a new token {idx}\")\n",
        "    ids = merge(ids, pair, idx)\n",
        "    merges[pair] = idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE5Hq2TARB69",
        "outputId": "774a8ea6-5cc2-4b91-961f-aefddc9934b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (101, 32) (e ) into a new token 128\n",
            "merging (115, 32) (s ) into a new token 129\n",
            "merging (97, 110) (an) into a new token 130\n",
            "merging (116, 104) (th) into a new token 131\n",
            "merging (100, 32) (d ) into a new token 132\n",
            "merging (105, 110) (in) into a new token 133\n",
            "merging (116, 32) (t ) into a new token 134\n",
            "merging (32, 115) ( s) into a new token 135\n",
            "merging (101, 110) (en) into a new token 136\n",
            "merging (105, 129) (i¬Å) into a new token 137\n",
            "merging (101, 114) (er) into a new token 138\n",
            "merging (130, 132) (¬Ç¬Ñ) into a new token 139\n",
            "merging (104, 128) (h¬Ä) into a new token 140\n",
            "merging (97, 114) (ar) into a new token 141\n",
            "merging (114, 101) (re) into a new token 142\n",
            "merging (46, 32) (. ) into a new token 143\n",
            "merging (44, 32) (, ) into a new token 144\n",
            "merging (84, 140) (T¬å) into a new token 145\n",
            "merging (111, 32) (o ) into a new token 146\n",
            "merging (111, 118) (ov) into a new token 147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_ZnnFtIRle_",
        "outputId": "26c3d034-8c96-4ac0-e09b-f55a0ae7524a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length: 1248\n",
            "ids length: 953\n",
            "compression ratio: 1.31X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In class activity: Take any text of your choice and implement the BPE algorithm. Report the compression ratio achieved."
      ],
      "metadata": {
        "id": "Vn555CG7XW7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the tiktoken library"
      ],
      "metadata": {
        "id": "lHJT8Uczcngk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tiktoken\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "# Text to encode and decode\n",
        "text = \"The lion roams in the jungle\"\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 1. GPT-2 Encoding/Decoding\n",
        "#    Using the \"gpt2\" encoding\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "tokenizer_gpt2 = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Encode: text -> list of token IDs\n",
        "token_ids_gpt2 = tokenizer_gpt2.encode(text)\n",
        "\n",
        "# Decode: list of token IDs -> original text (just to verify correctness)\n",
        "decoded_text_gpt2 = tokenizer_gpt2.decode(token_ids_gpt2)\n",
        "\n",
        "# We can also get each token string by decoding the IDs one by one\n",
        "tokens_gpt2 = [tokenizer_gpt2.decode([tid]) for tid in token_ids_gpt2]\n",
        "\n",
        "print(\"=== GPT-2 Encoding ===\")\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Token IDs:     \", token_ids_gpt2)\n",
        "print(\"Tokens:        \", tokens_gpt2)\n",
        "print(\"Decoded Text:  \", decoded_text_gpt2)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUm2SdUcXblG",
        "outputId": "0bda14ee-b44f-45a5-af61-46cab0563519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.8/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n",
            "=== GPT-2 Encoding ===\n",
            "Original Text:  The lion roams in the jungle\n",
            "Token IDs:      [464, 18744, 686, 4105, 287, 262, 20712]\n",
            "Tokens:         ['The', ' lion', ' ro', 'ams', ' in', ' the', ' jungle']\n",
            "Decoded Text:   The lion roams in the jungle\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2. GPT-3.5 Encoding\n",
        "#    Using the encoding_for_model(\"gpt-3.5-turbo\")\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "tokenizer_gpt35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "\n",
        "token_ids_gpt35 = tokenizer_gpt35.encode(text)\n",
        "decoded_text_gpt35 = tokenizer_gpt35.decode(token_ids_gpt35)\n",
        "tokens_gpt35 = [tokenizer_gpt35.decode([tid]) for tid in token_ids_gpt35]\n",
        "\n",
        "print(\"=== GPT-3.5 Encoding ===\")\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Token IDs:     \", token_ids_gpt35)\n",
        "print(\"Tokens:        \", tokens_gpt35)\n",
        "print(\"Decoded Text:  \", decoded_text_gpt35)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVHkblCLc2mG",
        "outputId": "b8a0cccc-4bcd-454e-bdbc-ea660359e766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPT-3.5 Encoding ===\n",
            "Original Text:  The lion roams in the jungle\n",
            "Token IDs:      [791, 40132, 938, 4214, 304, 279, 45520]\n",
            "Tokens:         ['The', ' lion', ' ro', 'ams', ' in', ' the', ' jungle']\n",
            "Decoded Text:   The lion roams in the jungle\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3. GPT-4 Encoding\n",
        "#    Using the encoding_for_model(\"gpt-4\")\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "tokenizer_gpt4 = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "\n",
        "token_ids_gpt4 = tokenizer_gpt4.encode(text)\n",
        "decoded_text_gpt4 = tokenizer_gpt4.decode(token_ids_gpt4)\n",
        "tokens_gpt4 = [tokenizer_gpt4.decode([tid]) for tid in token_ids_gpt4]\n",
        "\n",
        "print(\"=== GPT-4 Encoding ===\")\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Token IDs:     \", token_ids_gpt4)\n",
        "print(\"Tokens:        \", tokens_gpt4)\n",
        "print(\"Decoded Text:  \", decoded_text_gpt4)"
      ],
      "metadata": {
        "id": "wnhXtYvwc3PF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0711247-1fb6-4216-b945-ad5d500eadc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPT-4 Encoding ===\n",
            "Original Text:  The lion roams in the jungle\n",
            "Token IDs:      [791, 40132, 938, 4214, 304, 279, 45520]\n",
            "Tokens:         ['The', ' lion', ' ro', 'ams', ' in', ' the', ' jungle']\n",
            "Decoded Text:   The lion roams in the jungle\n"
          ]
        }
      ]
    }
  ]
}